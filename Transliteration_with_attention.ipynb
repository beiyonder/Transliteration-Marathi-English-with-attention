{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "VcFCqVJafpM6"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import string\n",
        "from string import digits\n",
        "import re\n",
        "from sklearn.utils import shuffle\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import LSTM, Input, Dense,Embedding, Concatenate, TimeDistributed\n",
        "from tensorflow.keras.models import Model,load_model, model_from_json\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.preprocessing.text import one_hot, Tokenizer\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import pickle as pkl\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pre-Processing and Transformation"
      ],
      "metadata": {
        "id": "XDUA0X--mawS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('mar.txt','r') as f:\n",
        "  data = f.read()"
      ],
      "metadata": {
        "id": "0HFpfCWKhoDi"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "uncleaned_data_list = data.split('\\n')\n",
        "len(uncleaned_data_list)\n",
        "uncleaned_data_list = uncleaned_data_list[:38695]\n",
        "len(uncleaned_data_list)\n",
        "english_word = []\n",
        "marathi_word = []\n",
        "cleaned_data_list = []\n",
        "for word in uncleaned_data_list:\n",
        "  english_word.append(word.split('\\t')[:-1][0])\n",
        "  marathi_word.append(word.split('\\t')[:-1][1])\n",
        "language_data = pd.DataFrame(columns=['English','Marathi'])\n",
        "language_data['English'] = english_word\n",
        "language_data['Marathi'] = marathi_word\n",
        "language_data.to_csv('language_data.csv', index=False)"
      ],
      "metadata": {
        "id": "CZibonsdmQmi"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "english_text = language_data['English'].values\n",
        "marathi_text = language_data['Marathi'].values\n",
        "len(english_text), len(marathi_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "didhdI2wmVrK",
        "outputId": "7a1dcc13-1cd0-45a8-da5c-c7f13cfa4e1f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7507, 7507)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Cleaning"
      ],
      "metadata": {
        "id": "SpWdZyadmih1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#to lower case\n",
        "english_text_ = [x.lower() for x in english_text]\n",
        "marathi_text_ = [x.lower() for x in marathi_text]\n",
        "#removing inverted commas\n",
        "english_text_ = [re.sub(\"'\",'',x) for x in english_text_]\n",
        "marathi_text_ = [re.sub(\"'\",'',x) for x in marathi_text_]\n",
        "def remove_punc(text_list):\n",
        "  table = str.maketrans('', '', string.punctuation)\n",
        "  removed_punc_text = []\n",
        "  for sent in text_list:\n",
        "    sentance = [w.translate(table) for w in sent.split(' ')]\n",
        "    removed_punc_text.append(' '.join(sentance))\n",
        "  return removed_punc_text\n",
        "english_text_ = remove_punc(english_text_)\n",
        "marathi_text_ = remove_punc(marathi_text_)\n",
        "remove_digits = str.maketrans('', '', digits)\n",
        "removed_digits_text = []\n",
        "for sent in english_text_:\n",
        "  sentance = [w.translate(remove_digits) for w in sent.split(' ')]\n",
        "  removed_digits_text.append(' '.join(sentance))\n",
        "english_text_ = removed_digits_text\n",
        "# removing the digits from the marathi sentances\n",
        "marathi_text_ = [re.sub(\"[२३०८१५७९४६]\",\"\",x) for x in marathi_text_]\n",
        "marathi_text_ = [re.sub(\"[\\u200d]\",\"\",x) for x in marathi_text_]\n",
        "# removing the stating and ending whitespaces\n",
        "english_text_ = [x.strip() for x in english_text_]\n",
        "marathi_text_ = [x.strip() for x in marathi_text_]"
      ],
      "metadata": {
        "id": "PxmF1Sm1mlVV"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adding ‘start’ and ‘end’ tag to marathi sentence."
      ],
      "metadata": {
        "id": "CLAPm_1omvH3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Putting the start and end words in the marathi sentances\n",
        "marathi_text_ = [\"start \" + x + \" end\" for x in marathi_text_]\n",
        "# manipulated_marathi_text_\n",
        "marathi_text_[0], english_text_[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "43nlgS59myHN",
        "outputId": "8573265b-10cd-4376-8418-27cf5c321f15"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('start जा end', 'go')"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preparation for Model Building"
      ],
      "metadata": {
        "id": "1TCoG3J6m3Eg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = english_text_\n",
        "Y = marathi_text_\n",
        "X_train, X_test, y_train, y_test=train_test_split(X,Y,test_size=0.1)"
      ],
      "metadata": {
        "id": "6cdffzl5m879"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "determine the maximum length of our sentences in both English and Marathi"
      ],
      "metadata": {
        "id": "iuT0n2ZNnCj-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Max_length(data):\n",
        "  max_length_ = max([len(x.split(' ')) for x in data])\n",
        "  return max_length_\n",
        "#Training data\n",
        "max_length_english = Max_length(X_train)\n",
        "max_length_marathi = Max_length(y_train)\n",
        "#Test data\n",
        "max_length_english_test = Max_length(X_test)\n",
        "max_length_marathi_test = Max_length(y_test)\n",
        "max_length_marathi, max_length_english"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2UkmM1SSnFq2",
        "outputId": "176c98b4-4dcf-429b-b2a2-38ad590a8ce5"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9, 5)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tokenization"
      ],
      "metadata": {
        "id": "Imq17LhSnJZm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# convert string input to a numerical list\n",
        "# using Tokenizer in the keras-preprocessing library.\n",
        "\"\"\"\n",
        "it is mandatory to have an equal length of all input sequences in sequence-to-sequence models.\n",
        "So, we will pad extra ‘0s’ to make the sequence of the same length. This would be done by pad_sequence\n",
        "\"\"\"\n",
        "\n",
        "englishTokenizer = Tokenizer()\n",
        "englishTokenizer.fit_on_texts(X_train)\n",
        "Eword2index = englishTokenizer.word_index\n",
        "vocab_size_source = len(Eword2index) + 1\n",
        "X_train = englishTokenizer.texts_to_sequences(X_train)\n",
        "X_train = pad_sequences(X_train, maxlen=max_length_english, padding='post')\n",
        "X_test = englishTokenizer.texts_to_sequences(X_test)\n",
        "X_test = pad_sequences(X_test, maxlen = max_length_english, padding='post')\n",
        "marathiTokenizer = Tokenizer()\n",
        "marathiTokenizer.fit_on_texts(y_train)\n",
        "Mword2index = marathiTokenizer.word_index\n",
        "vocab_size_target = len(Mword2index) + 1\n",
        "y_train = marathiTokenizer.texts_to_sequences(y_train)\n",
        "y_train = pad_sequences(y_train, maxlen=max_length_marathi, padding='post')\n",
        "y_test = marathiTokenizer.texts_to_sequences(y_test)\n",
        "y_test = pad_sequences(y_test, maxlen = max_length_marathi, padding='post')\n",
        "vocab_size_source, vocab_size_target"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KluLn8-0nNVm",
        "outputId": "3ccae89e-ad5a-43f7-82bd-185d46cab84d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1565, 2916)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train[0], y_train[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pCtXPAzYn6W7",
        "outputId": "7036d630-876c-4072-cf90-2fc3c1660d4a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([ 19,   4, 190,   0,   0], dtype=int32),\n",
              " array([  1, 158,  25,   7,   2,   0,   0,   0,   0], dtype=int32))"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To save our preprocessing time whenever we reuse it again in future, we will save our important attributes"
      ],
      "metadata": {
        "id": "yFQ5kDXeoBVt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('NMT_data.pkl','wb') as f:\n",
        "  pkl.dump([X_train, y_train, X_test, y_test],f)\n",
        "with open('NMT_Etokenizer.pkl','wb') as f:\n",
        "  pkl.dump([vocab_size_source, Eword2index, englishTokenizer], f)\n",
        "with open('NMT_Mtokenizer.pkl', 'wb') as f:\n",
        "  pkl.dump([vocab_size_target, Mword2index, marathiTokenizer], f)\n",
        "X_train = np.array(X_train)\n",
        "y_train = np.array(y_train)\n",
        "X_test = np.array(X_test)\n",
        "y_test = np.array(y_test)"
      ],
      "metadata": {
        "id": "grb0MJpeoDgN"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9n5fRfq8pFzt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Keras does not officially support attention layer. we can either implement our own attention layer or use a third-party implementation."
      ],
      "metadata": {
        "id": "vb_lwd9ooPDV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.python.keras import backend as K\n",
        "\n",
        "logger = tf.get_logger()\n",
        "\n",
        "class AttentionLayer(tf.keras.layers.Layer):\n",
        "    \"\"\"\n",
        "    This class implements Bahdanau attention (https://arxiv.org/pdf/1409.0473.pdf).\n",
        "    There are three sets of weights introduced W_a, U_a, and V_a\n",
        "     \"\"\"\n",
        "\n",
        "    def __init__(self, **kwargs):\n",
        "        super(AttentionLayer, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        assert isinstance(input_shape, list)\n",
        "        # Create a trainable weight variable for this layer.\n",
        "\n",
        "        self.W_a = self.add_weight(name='W_a',\n",
        "                                   shape=tf.TensorShape((input_shape[0][2], input_shape[0][2])),\n",
        "                                   initializer='uniform',\n",
        "                                   trainable=True)\n",
        "        self.U_a = self.add_weight(name='U_a',\n",
        "                                   shape=tf.TensorShape((input_shape[1][2], input_shape[0][2])),\n",
        "                                   initializer='uniform',\n",
        "                                   trainable=True)\n",
        "        self.V_a = self.add_weight(name='V_a',\n",
        "                                   shape=tf.TensorShape((input_shape[0][2], 1)),\n",
        "                                   initializer='uniform',\n",
        "                                   trainable=True)\n",
        "\n",
        "        super(AttentionLayer, self).build(input_shape)  # Be sure to call this at the end\n",
        "\n",
        "    def call(self, inputs):\n",
        "        \"\"\"\n",
        "        inputs: [encoder_output_sequence, decoder_output_sequence]\n",
        "        \"\"\"\n",
        "        assert type(inputs) == list\n",
        "        encoder_out_seq, decoder_out_seq = inputs\n",
        "\n",
        "        logger.debug(f\"encoder_out_seq.shape = {encoder_out_seq.shape}\")\n",
        "        logger.debug(f\"decoder_out_seq.shape = {decoder_out_seq.shape}\")\n",
        "\n",
        "        def energy_step(inputs, states):\n",
        "            \"\"\" Step function for computing energy for a single decoder state\n",
        "            inputs: (batchsize * 1 * de_in_dim)\n",
        "            states: (batchsize * 1 * de_latent_dim)\n",
        "            \"\"\"\n",
        "\n",
        "            logger.debug(\"Running energy computation step\")\n",
        "\n",
        "            if not isinstance(states, (list, tuple)):\n",
        "                raise TypeError(f\"States must be an iterable. Got {states} of type {type(states)}\")\n",
        "\n",
        "            encoder_full_seq = states[-1]\n",
        "\n",
        "            \"\"\" Computing S.Wa where S=[s0, s1, ..., si]\"\"\"\n",
        "            # <= batch size * en_seq_len * latent_dim\n",
        "            W_a_dot_s = K.dot(encoder_full_seq, self.W_a)\n",
        "\n",
        "            \"\"\" Computing hj.Ua \"\"\"\n",
        "            U_a_dot_h = K.expand_dims(K.dot(inputs, self.U_a), 1)  # <= batch_size, 1, latent_dim\n",
        "\n",
        "            logger.debug(f\"U_a_dot_h.shape = {U_a_dot_h.shape}\")\n",
        "\n",
        "            \"\"\" tanh(S.Wa + hj.Ua) \"\"\"\n",
        "            # <= batch_size*en_seq_len, latent_dim\n",
        "            Ws_plus_Uh = K.tanh(W_a_dot_s + U_a_dot_h)\n",
        "\n",
        "            logger.debug(f\"Ws_plus_Uh.shape = {Ws_plus_Uh.shape}\")\n",
        "\n",
        "            \"\"\" softmax(va.tanh(S.Wa + hj.Ua)) \"\"\"\n",
        "            # <= batch_size, en_seq_len\n",
        "            e_i = K.squeeze(K.dot(Ws_plus_Uh, self.V_a), axis=-1)\n",
        "            # <= batch_size, en_seq_len\n",
        "            e_i = K.softmax(e_i)\n",
        "\n",
        "            logger.debug(f\"ei.shape = {e_i.shape}\")\n",
        "\n",
        "            return e_i, [e_i]\n",
        "\n",
        "        def context_step(inputs, states):\n",
        "            \"\"\" Step function for computing ci using ei \"\"\"\n",
        "\n",
        "            logger.debug(\"Running attention vector computation step\")\n",
        "\n",
        "            if not isinstance(states, (list, tuple)):\n",
        "                raise TypeError(f\"States must be an iterable. Got {states} of type {type(states)}\")\n",
        "\n",
        "            encoder_full_seq = states[-1]\n",
        "\n",
        "            # <= batch_size, hidden_size\n",
        "            c_i = K.sum(encoder_full_seq * K.expand_dims(inputs, -1), axis=1)\n",
        "\n",
        "            logger.debug(f\"ci.shape = {c_i.shape}\")\n",
        "\n",
        "            return c_i, [c_i]\n",
        "\n",
        "        # we don't maintain states between steps when computing attention\n",
        "        # attention is stateless, so we're passing a fake state for RNN step function\n",
        "        fake_state_c = K.sum(encoder_out_seq, axis=1)\n",
        "        fake_state_e = K.sum(encoder_out_seq, axis=2)  # <= (batch_size, enc_seq_len, latent_dim\n",
        "\n",
        "        \"\"\" Computing energy outputs \"\"\"\n",
        "        # e_outputs => (batch_size, de_seq_len, en_seq_len)\n",
        "        last_out, e_outputs, _ = K.rnn(\n",
        "            energy_step, decoder_out_seq, [fake_state_e], constants=[encoder_out_seq]\n",
        "        )\n",
        "\n",
        "        \"\"\" Computing context vectors \"\"\"\n",
        "        last_out, c_outputs, _ = K.rnn(\n",
        "            context_step, e_outputs, [fake_state_c], constants=[encoder_out_seq]\n",
        "        )\n",
        "\n",
        "        return c_outputs, e_outputs\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        \"\"\" Outputs produced by the layer \"\"\"\n",
        "        return [\n",
        "            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[1][2])),\n",
        "            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[0][1]))\n",
        "        ]"
      ],
      "metadata": {
        "id": "MPw2XNsopH01"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pydot"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XzIZmCJKtEwx",
        "outputId": "078757e9-f9a0-4ff1-8b21-4d2207720096"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pydot\n",
            "  Downloading pydot-2.0.0-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: pyparsing>=3 in /usr/local/lib/python3.10/dist-packages (from pydot) (3.1.2)\n",
            "Installing collected packages: pydot\n",
            "Successfully installed pydot-2.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install graphviz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CjpheDBVtlbb",
        "outputId": "58f7a965-dd8b-4392-b166-eb9ddeaa4ac7"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting graphviz\n",
            "  Downloading graphviz-0.20.3-py3-none-any.whl (47 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.1/47.1 kB\u001b[0m \u001b[31m697.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: graphviz\n",
            "Successfully installed graphviz-0.20.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pydot\n",
        "import graphviz\n",
        "K.clear_session()\n",
        "latent_dim = 500\n",
        "# Encoder\n",
        "encoder_inputs = Input(shape=(max_length_english,))\n",
        "enc_emb = Embedding(vocab_size_source, latent_dim,trainable=True)(encoder_inputs)\n",
        "#LSTM 1\n",
        "encoder_lstm1 = LSTM(latent_dim,return_sequences=True,return_state=True)\n",
        "encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb)\n",
        "#LSTM 2\n",
        "encoder_lstm2 = LSTM(latent_dim,return_sequences=True,return_state=True)\n",
        "encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1)\n",
        "#LSTM 3\n",
        "encoder_lstm3=LSTM(latent_dim, return_state=True, return_sequences=True)\n",
        "encoder_outputs, state_h, state_c= encoder_lstm3(encoder_output2)\n",
        "# Set up the decoder.\n",
        "decoder_inputs = Input(shape=(None,))\n",
        "dec_emb_layer = Embedding(vocab_size_target, latent_dim,trainable=True)\n",
        "dec_emb = dec_emb_layer(decoder_inputs)\n",
        "#LSTM using encoder_states as initial state\n",
        "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
        "decoder_outputs,decoder_fwd_state, decoder_back_state = decoder_lstm(dec_emb,initial_state=[state_h, state_c])\n",
        "#Attention Layer\n",
        "attn_layer = AttentionLayer(name='attention_layer')\n",
        "attn_out, attn_states = attn_layer([encoder_outputs, decoder_outputs])\n",
        "# Concat attention output and decoder LSTM output\n",
        "decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attn_out])\n",
        "#Dense layer\n",
        "decoder_dense = TimeDistributed(Dense(vocab_size_target, activation='softmax'))\n",
        "decoder_outputs = decoder_dense(decoder_concat_input)\n",
        "# Define the model\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "plot_model(model, to_file='train_model.png', show_shapes=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "48TdljIzoP65",
        "outputId": "3cb0909b-3083-4f70-efe6-f111bed5493c"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='rmsprop',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "y9k9GAZqpcJ_"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Training"
      ],
      "metadata": {
        "id": "S4R492yxpfj0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1)"
      ],
      "metadata": {
        "id": "6ZqgFNbhpe6k"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit([X_train, y_train[:,:-1]], y_train.reshape(y_train.shape[0], y_train.shape[1],1)[:,1:],\n",
        "                    epochs=50,\n",
        "                    callbacks=[es],\n",
        "                    batch_size=512,\n",
        "                    validation_data = ([X_test, y_test[:,:-1]], y_test.reshape(y_test.shape[0], y_test.shape[1], 1)[:,1:]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xpAbXzP1pmp0",
        "outputId": "cb18ac7b-76aa-4c94-f094-ce3adeff68d3"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "14/14 [==============================] - 16s 622ms/step - loss: 6.0327 - accuracy: 0.4404 - val_loss: 3.1665 - val_accuracy: 0.5005\n",
            "Epoch 2/50\n",
            "14/14 [==============================] - 7s 492ms/step - loss: 3.1779 - accuracy: 0.4930 - val_loss: 2.8718 - val_accuracy: 0.5604\n",
            "Epoch 3/50\n",
            "14/14 [==============================] - 7s 497ms/step - loss: 2.9536 - accuracy: 0.5361 - val_loss: 2.6961 - val_accuracy: 0.5604\n",
            "Epoch 4/50\n",
            "14/14 [==============================] - 7s 496ms/step - loss: 2.8112 - accuracy: 0.5433 - val_loss: 2.6314 - val_accuracy: 0.5694\n",
            "Epoch 5/50\n",
            "14/14 [==============================] - 7s 494ms/step - loss: 2.7301 - accuracy: 0.5481 - val_loss: 2.5644 - val_accuracy: 0.5871\n",
            "Epoch 6/50\n",
            "14/14 [==============================] - 7s 486ms/step - loss: 2.6627 - accuracy: 0.5580 - val_loss: 2.5201 - val_accuracy: 0.5887\n",
            "Epoch 7/50\n",
            "14/14 [==============================] - 7s 497ms/step - loss: 2.5900 - accuracy: 0.5858 - val_loss: 2.4509 - val_accuracy: 0.6027\n",
            "Epoch 8/50\n",
            "14/14 [==============================] - 7s 493ms/step - loss: 2.4987 - accuracy: 0.6078 - val_loss: 2.3637 - val_accuracy: 0.6337\n",
            "Epoch 9/50\n",
            "14/14 [==============================] - 7s 497ms/step - loss: 2.4561 - accuracy: 0.6192 - val_loss: 2.3489 - val_accuracy: 0.6372\n",
            "Epoch 10/50\n",
            "14/14 [==============================] - 7s 491ms/step - loss: 2.4200 - accuracy: 0.6241 - val_loss: 2.3231 - val_accuracy: 0.6348\n",
            "Epoch 11/50\n",
            "14/14 [==============================] - 7s 492ms/step - loss: 2.3949 - accuracy: 0.6248 - val_loss: 2.3035 - val_accuracy: 0.6357\n",
            "Epoch 12/50\n",
            "14/14 [==============================] - 7s 492ms/step - loss: 2.3826 - accuracy: 0.6264 - val_loss: 2.2690 - val_accuracy: 0.6368\n",
            "Epoch 13/50\n",
            "14/14 [==============================] - 7s 498ms/step - loss: 2.3608 - accuracy: 0.6264 - val_loss: 2.2465 - val_accuracy: 0.6420\n",
            "Epoch 14/50\n",
            "14/14 [==============================] - 7s 493ms/step - loss: 2.3526 - accuracy: 0.6283 - val_loss: 2.2431 - val_accuracy: 0.6383\n",
            "Epoch 15/50\n",
            "14/14 [==============================] - 7s 497ms/step - loss: 2.3301 - accuracy: 0.6301 - val_loss: 2.2767 - val_accuracy: 0.6352\n",
            "Epoch 15: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot\n",
        "pyplot.plot(history.history['loss'], label='train')\n",
        "pyplot.plot(history.history['val_loss'], label='test')\n",
        "pyplot.legend()\n",
        "pyplot.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "_TX3WIT5uYw7",
        "outputId": "9d27fa6c-1380-4c1e-b398-9363d0c92545"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Saving and Loading.\n",
        "save the trained model with proper weights."
      ],
      "metadata": {
        "id": "w-Lrgwruulmc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_json = model.to_json()\n",
        "with open(\"NMT_model.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "# serialize weights to HDF5\n",
        "model.save_weights(\"NMT_model_weight.h5\")\n",
        "print(\"Saved model to disk\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9_dKMEE0ukQl",
        "outputId": "47f9585a-d03c-41ec-8e62-d76c7b9378c5"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved model to disk\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load model"
      ],
      "metadata": {
        "id": "7WKmIZfKuy31"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# loading the model architecture and asigning the weights\n",
        "json_file = open('NMT_model.json', 'r')\n",
        "loaded_model_json = json_file.read()\n",
        "json_file.close()\n",
        "model_loaded = model_from_json(loaded_model_json, custom_objects={'AttentionLayer': AttentionLayer})\n",
        "# load weights into new model\n",
        "model_loaded.load_weights(\"NMT_model_weight.h5\")"
      ],
      "metadata": {
        "id": "KOlz9jQXu0oE"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inference Model.\n",
        "=> to predict our output sequences by considering weights from a pre-trained model."
      ],
      "metadata": {
        "id": "jT0UAgaDu3pl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "latent_dim=500\n",
        "# encoder inference\n",
        "encoder_inputs = model_loaded.input[0]  #loading encoder_inputs\n",
        "encoder_outputs, state_h, state_c = model_loaded.layers[6].output #loading encoder_outputs\n",
        "#print(encoder_outputs.shape)\n",
        "encoder_model = Model(inputs=encoder_inputs,outputs=[encoder_outputs, state_h, state_c])\n",
        "# decoder inference\n",
        "# Below tensors will hold the states of the previous time step\n",
        "decoder_state_input_h = Input(shape=(latent_dim,))\n",
        "decoder_state_input_c = Input(shape=(latent_dim,))\n",
        "decoder_hidden_state_input = Input(shape=(32,latent_dim))\n",
        "# Get the embeddings of the decoder sequence\n",
        "decoder_inputs = model_loaded.layers[3].output\n",
        "#print(decoder_inputs.shape)\n",
        "dec_emb_layer = model_loaded.layers[5]\n",
        "dec_emb2= dec_emb_layer(decoder_inputs)\n",
        "# To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
        "decoder_lstm = model_loaded.layers[7]\n",
        "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c])\n",
        "#attention inference\n",
        "attn_layer = model_loaded.layers[8]\n",
        "attn_out_inf, attn_states_inf = attn_layer([decoder_hidden_state_input, decoder_outputs2])\n",
        "concate = model_loaded.layers[9]\n",
        "decoder_inf_concat = concate([decoder_outputs2, attn_out_inf])\n",
        "# A dense softmax layer to generate prob dist. over the target vocabulary\n",
        "decoder_dense = model_loaded.layers[10]\n",
        "decoder_outputs2 = decoder_dense(decoder_inf_concat)\n",
        "# Final decoder model\n",
        "decoder_model = Model(\n",
        "[decoder_inputs] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c],\n",
        "[decoder_outputs2] + [state_h2, state_c2])"
      ],
      "metadata": {
        "id": "Y3ygpflau6bt"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predcitions"
      ],
      "metadata": {
        "id": "cGHeOA-4vMfW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def decode_sequence(input_seq):\n",
        "    # Encode the input as state vectors.\n",
        "    e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
        "\n",
        "    # Generate empty target sequence of length 1.\n",
        "    target_seq = np.zeros((1, 1))\n",
        "\n",
        "    # Chose the 'start' word as the first word of the target sequence\n",
        "    target_seq[0, 0] = Mword2index['start']\n",
        "\n",
        "    stop_condition = False\n",
        "    decoded_sentence = ''\n",
        "\n",
        "    while not stop_condition:\n",
        "        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n",
        "\n",
        "        # Sample a token\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        if sampled_token_index == 0:\n",
        "            break\n",
        "        else:\n",
        "            sampled_token = Mindex2word[sampled_token_index]\n",
        "            if sampled_token != 'end':\n",
        "                decoded_sentence += ' ' + sampled_token\n",
        "\n",
        "            # Exit condition: either hit max length or find stop word.\n",
        "            if sampled_token == 'end' or len(decoded_sentence.split()) >= (26 - 1):\n",
        "                stop_condition = True\n",
        "\n",
        "            # Update the target sequence (of length 1).\n",
        "            target_seq = np.zeros((1, 1))\n",
        "            target_seq[0, 0] = sampled_token_index\n",
        "\n",
        "            # Update internal states\n",
        "            e_h, e_c = h, c\n",
        "\n",
        "    return decoded_sentence\n"
      ],
      "metadata": {
        "id": "sCcKH0rwvPRA"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Forming a reverse vocabulary"
      ],
      "metadata": {
        "id": "gxNpkgl5vnQx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Eindex2word = englishTokenizer.index_word\n",
        "Mindex2word = marathiTokenizer.index_word"
      ],
      "metadata": {
        "id": "iXlaI2yUvpo1"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Some transformation before giving a string to the function"
      ],
      "metadata": {
        "id": "gClh5V5EvtrV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def seq2summary(input_seq):\n",
        "    newString=''\n",
        "    for i in input_seq:\n",
        "      if((i!=0 and i!=Mword2index['start']) and i!=Mword2index['end']):\n",
        "        newString=newString+Mindex2word[i]+' '\n",
        "    return newString\n",
        "def seq2text(input_seq):\n",
        "    newString=''\n",
        "    for i in input_seq:\n",
        "      if(i!=0):\n",
        "        newString=newString+Eindex2word[i]+' '\n",
        "    return newString"
      ],
      "metadata": {
        "id": "iOJ8-WLWvuWc"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Call the necessary functions to test the translation model"
      ],
      "metadata": {
        "id": "99727GpHvzor"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Encoder\n",
        "encoder_inputs = Input(shape=(max_length_english,))\n",
        "\n",
        "# Decoder\n",
        "decoder_inputs = Input(shape=(None,))\n",
        "print(encoder_inputs)\n",
        "print(decoder_inputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bPCmwjjdzFWl",
        "outputId": "b7e4c86a-8a44-48b6-d82a-0ca7296da47c"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KerasTensor(type_spec=TensorSpec(shape=(None, 5), dtype=tf.float32, name='input_14'), name='input_14', description=\"created by layer 'input_14'\")\n",
            "KerasTensor(type_spec=TensorSpec(shape=(None, None), dtype=tf.float32, name='input_15'), name='input_15', description=\"created by layer 'input_15'\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wtLIJmynzeV8",
        "outputId": "62e3780b-436e-4830-befe-fde2c2e53abd"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_5 (InputLayer)        [(None, 5)]                  0         []                            \n",
            "                                                                                                  \n",
            " embedding (Embedding)       (None, 5, 500)               782500    ['input_5[0][0]']             \n",
            "                                                                                                  \n",
            " lstm (LSTM)                 [(None, 5, 500),             2002000   ['embedding[0][0]']           \n",
            "                              (None, 500),                                                        \n",
            "                              (None, 500)]                                                        \n",
            "                                                                                                  \n",
            " input_6 (InputLayer)        [(None, None)]               0         []                            \n",
            "                                                                                                  \n",
            " lstm_1 (LSTM)               [(None, 5, 500),             2002000   ['lstm[0][0]']                \n",
            "                              (None, 500),                                                        \n",
            "                              (None, 500)]                                                        \n",
            "                                                                                                  \n",
            " embedding_1 (Embedding)     (None, None, 500)            1458000   ['input_6[0][0]']             \n",
            "                                                                                                  \n",
            " lstm_2 (LSTM)               [(None, 5, 500),             2002000   ['lstm_1[0][0]']              \n",
            "                              (None, 500),                                                        \n",
            "                              (None, 500)]                                                        \n",
            "                                                                                                  \n",
            " lstm_3 (LSTM)               [(None, None, 500),          2002000   ['embedding_1[0][0]',         \n",
            "                              (None, 500),                           'lstm_2[0][1]',              \n",
            "                              (None, 500)]                           'lstm_2[0][2]']              \n",
            "                                                                                                  \n",
            " attention_layer (Attention  ((None, None, 500),          500500    ['lstm_2[0][0]',              \n",
            " Layer)                       (None, None, 5))                       'lstm_3[0][0]']              \n",
            "                                                                                                  \n",
            " concat_layer (Concatenate)  (None, None, 1000)           0         ['lstm_3[0][0]',              \n",
            "                                                                     'attention_layer[0][0]']     \n",
            "                                                                                                  \n",
            " time_distributed (TimeDist  (None, None, 2916)           2918916   ['concat_layer[0][0]']        \n",
            " ributed)                                                                                         \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 13667916 (52.14 MB)\n",
            "Trainable params: 13667916 (52.14 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the maximum length expected by the model\n",
        "max_length_english = 32  # Update this if your model expects a different length\n",
        "max_length_marathi = 32  # Update this if your model expects a different length\n",
        "\n",
        "# Padding training and test data\n",
        "# X_train_padded = pad_sequences(X_train, maxlen=max_length_english, padding='post')\n",
        "X_test_padded = pad_sequences(X_test, maxlen=max_length_english, padding='post')\n",
        "y_train_padded = pad_sequences(y_train, maxlen=max_length_marathi, padding='post')\n",
        "y_test_padded = pad_sequences(y_test, maxlen=max_length_marathi, padding='post')\n",
        "\n",
        "# Adjust the loop for the test data\n",
        "for i in range(10):\n",
        "    print(\"Review:\", seq2text(X_test_padded[i]))\n",
        "    print(\"Original summary:\", seq2summary(y_test[i]))\n",
        "    print(\"Predicted summary:\", decode_sequence(X_test_padded[i].reshape(1, max_length_english)))\n",
        "    print(\"\\n\")\n",
        "\n",
        "# max_length = 32\n",
        "# X_test_padded = pad_sequences(X_test, maxlen = max_length, padding='post')\n",
        "# for i in range(10):\n",
        "#   print(\"Review:\",seq2text(X_test_padded[i]))\n",
        "#   print(\"Original summary:\",seq2summary(y_test[i]))\n",
        "#   print(\"Predicted summary:\",decode_sequence(X_test_padded[i].reshape(1,max_length)))\n",
        "#   print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "wCz3qsyxv3sk",
        "outputId": "a6097d4c-4f1f-411d-c38a-8e0d61bfcea4"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Review: i read your book \n",
            "Original summary: मी तुमचं पुस्तक वाचलं \n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "Predicted summary:  मी मी मी मला मला आहे\n",
            "\n",
            "\n",
            "Review: the food is cold \n",
            "Original summary: ते खाणं थंड आहे \n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "Predicted summary:  थांबलं मी मी मी मी मी मी मी मी मी मी मी मी मी मी मी मी मी मी मी मी मी मी मी मी\n",
            "\n",
            "\n",
            "Review: i have a dog \n",
            "Original summary: माझ्याकडे कुत्रा आहे \n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "Predicted summary:  मी मी मी मला मला आहे\n",
            "\n",
            "\n",
            "Review: copy this file \n",
            "Original summary: ही फाइल कॉपी करा \n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "Predicted summary:  मी मी मी मला मला आहे\n",
            "\n",
            "\n",
            "Review: this is my book \n",
            "Original summary: हे माझं पुस्तक आहे \n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "Predicted summary:  मी मी मी मला मला आहे\n",
            "\n",
            "\n",
            "Review: how is it \n",
            "Original summary: कसं आहे \n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "Predicted summary:  थांबलं थांबलं जराशी जराशी जराशी जराशी जराशी जराशी जराशी जराशी जराशी जराशी जराशी जराशी जराशी जराशी जराशी जराशी जराशी जराशी जराशी जराशी जराशी जराशी जराशी\n",
            "\n",
            "\n",
            "Review: were you crying \n",
            "Original summary: तू रडत होतास का \n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "Predicted summary:  मी मी मी मला मला आहे\n",
            "\n",
            "\n",
            "Review: i my breath \n",
            "Original summary: मी माझा श्वास \n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "Predicted summary:  मी मी मी मला मला आहे\n",
            "\n",
            "\n",
            "Review: a dog is \n",
            "Original summary: कुत्रा आहे \n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "Predicted summary:  मी मी मी मला मला आहे\n",
            "\n",
            "\n",
            "Review: there is more \n",
            "Original summary: आजून आहे \n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "Predicted summary:  मी मी मी मला आहे\n",
            "\n",
            "\n"
          ]
        }
      ]
    }
  ]
}